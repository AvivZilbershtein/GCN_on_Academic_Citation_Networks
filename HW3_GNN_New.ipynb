{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on Academic Citation Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References : https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX#scrollTo=8zOh6IIeI3Op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HW3Dataset(Dataset):\n",
    "    url = 'https://technionmail-my.sharepoint.com/:u:/g/personal/ploznik_campus_technion_ac_il/EUHUDSoVnitIrEA6ALsAK1QBpphP5jX3OmGyZAgnbUFo0A?download=1'\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(HW3Dataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        file_url = self.url.replace(' ', '%20')\n",
    "        response = requests.get(file_url)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Failed to download the file, status code: {response.status_code}\")\n",
    "\n",
    "        with open(os.path.join(self.raw_dir, self.raw_file_names[0]), 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "    def process(self):\n",
    "        raw_path = os.path.join(self.raw_dir, self.raw_file_names[0])\n",
    "        data = torch.load(raw_path)\n",
    "        torch.save(data, self.processed_paths[0])\n",
    "\n",
    "    def len(self):\n",
    "        return 1\n",
    "\n",
    "    def get(self, idx):\n",
    "        return torch.load(self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[100000, 128], edge_index=[2, 444288], y=[100000, 1], node_year=[100000, 1], train_mask=[80000], val_mask=[20000])\n"
     ]
    }
   ],
   "source": [
    "dataset = HW3Dataset(root='data/hw3_new/')\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Analysis on the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 100000\n",
      "Number of edges: 444288\n",
      "Average node degree: 4.44\n",
      "Number of training nodes: 80000\n",
      "Training node label rate: 31999.60\n",
      "Has self-loops: False\n",
      "Is undirected: False\n"
     ]
    }
   ],
   "source": [
    "# Gather some statistics about the graph\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.shape[0]}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = to_networkx(data, to_undirected=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Our Graph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACC</th>\n",
       "      <td>0.121265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average In Degree</th>\n",
       "      <td>4.442880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Out Degree</th>\n",
       "      <td>4.442880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Our Graph\n",
       "ACC                  0.121265\n",
       "Average In Degree    4.442880\n",
       "Average Out Degree   4.442880"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {\n",
    "    \"ACC\": [nx.average_clustering(G)],\n",
    "    \"Average In Degree\": [np.mean(np.array([G.in_degree(n) for n in G.nodes()]))],\n",
    "    \"Average Out Degree\": [np.mean(np.array([G.out_degree(n) for n in G.nodes()]))],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "results_df.columns = [\"Our Graph\"]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCN with Tanh activation function and its' train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(128, 32)\n",
      "  (conv2): GCNConv(32, 32)\n",
      "  (conv3): GCNConv(32, 16)\n",
      "  (classifier): Linear(in_features=16, out_features=40, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels//2)\n",
    "        self.classifier = Linear(hidden_channels//2, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        \n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = GCN(32)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanh Hidden channels = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 3.7067\n",
      "Epoch: 11, Loss: 3.2249\n",
      "Epoch: 21, Loss: 2.9345\n",
      "Epoch: 31, Loss: 2.7440\n",
      "Epoch: 41, Loss: 2.5635\n",
      "Epoch: 51, Loss: 2.3945\n",
      "Epoch: 61, Loss: 2.2556\n",
      "Epoch: 71, Loss: 2.1358\n",
      "Epoch: 81, Loss: 2.0409\n",
      "Epoch: 91, Loss: 1.9668\n",
      "Epoch: 101, Loss: 1.9086\n",
      "Epoch: 111, Loss: 1.8635\n",
      "Epoch: 121, Loss: 1.8320\n",
      "Epoch: 131, Loss: 1.8019\n",
      "Epoch: 141, Loss: 1.7795\n",
      "Epoch: 151, Loss: 1.7658\n",
      "Epoch: 161, Loss: 1.7490\n",
      "Epoch: 171, Loss: 1.7354\n",
      "Epoch: 181, Loss: 1.7400\n",
      "Epoch: 191, Loss: 1.7161\n",
      "Epoch: 201, Loss: 1.7074\n",
      "Epoch: 211, Loss: 1.6989\n",
      "Epoch: 221, Loss: 1.6887\n",
      "Epoch: 231, Loss: 1.6806\n",
      "Epoch: 241, Loss: 1.6878\n",
      "Epoch: 251, Loss: 1.6682\n",
      "Epoch: 261, Loss: 1.6579\n",
      "Epoch: 271, Loss: 1.6508\n",
      "Epoch: 281, Loss: 1.6442\n",
      "Epoch: 291, Loss: 1.6381\n",
      "Epoch: 301, Loss: 1.6469\n",
      "Epoch: 311, Loss: 1.6294\n",
      "Epoch: 321, Loss: 1.6248\n",
      "Epoch: 331, Loss: 1.6202\n",
      "Epoch: 341, Loss: 1.6163\n",
      "Epoch: 351, Loss: 1.6206\n",
      "Epoch: 361, Loss: 1.6122\n",
      "Epoch: 371, Loss: 1.6073\n",
      "Epoch: 381, Loss: 1.6076\n",
      "Epoch: 391, Loss: 1.6070\n",
      "Epoch: 401, Loss: 1.5999\n",
      "Epoch: 411, Loss: 1.5971\n",
      "Epoch: 421, Loss: 1.5951\n",
      "Epoch: 431, Loss: 1.5929\n",
      "Epoch: 441, Loss: 1.6386\n",
      "Epoch: 451, Loss: 1.6004\n",
      "Epoch: 461, Loss: 1.5906\n",
      "Epoch: 471, Loss: 1.5885\n",
      "Epoch: 481, Loss: 1.5866\n",
      "Epoch: 491, Loss: 1.5845\n",
      "Validation Accuracy: 0.5345\n",
      "Minimum Loss Value: 1.5831\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(323)\n",
    "model = GCN(16) # changing the hidden channels number to a value from [16,32,64]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    a = data.y[data.train_mask].resize_(len(data.train_mask))\n",
    "    loss = criterion(out[data.train_mask], a)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    b = data.y[data.val_mask].resize_(len(data.val_mask))\n",
    "    test_correct = pred[data.val_mask] == b\n",
    "    test_acc = int(test_correct.sum()) / len(data.val_mask)\n",
    "    return test_acc\n",
    "\n",
    "total_loss = []\n",
    "for i, epoch in enumerate(range(1, 501)):\n",
    "    loss = train()\n",
    "    total_loss.append(loss)\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}')\n",
    "val_acc = test()\n",
    "print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "print(f'Minimum Loss Value: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanh Hidden channels = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 3.7397\n",
      "Epoch: 11, Loss: 3.0289\n",
      "Epoch: 21, Loss: 2.7654\n",
      "Epoch: 31, Loss: 2.4860\n",
      "Epoch: 41, Loss: 2.2601\n",
      "Epoch: 51, Loss: 2.0983\n",
      "Epoch: 61, Loss: 1.9686\n",
      "Epoch: 71, Loss: 1.8724\n",
      "Epoch: 81, Loss: 1.8058\n",
      "Epoch: 91, Loss: 1.7501\n",
      "Epoch: 101, Loss: 1.7081\n",
      "Epoch: 111, Loss: 1.6736\n",
      "Epoch: 121, Loss: 1.6520\n",
      "Epoch: 131, Loss: 1.6279\n",
      "Epoch: 141, Loss: 1.6097\n",
      "Epoch: 151, Loss: 1.5942\n",
      "Epoch: 161, Loss: 1.5806\n",
      "Epoch: 171, Loss: 1.5856\n",
      "Epoch: 181, Loss: 1.5614\n",
      "Epoch: 191, Loss: 1.5488\n",
      "Epoch: 201, Loss: 1.5414\n",
      "Epoch: 211, Loss: 1.5317\n",
      "Epoch: 221, Loss: 1.5239\n",
      "Epoch: 231, Loss: 1.5165\n",
      "Epoch: 241, Loss: 1.5098\n",
      "Epoch: 251, Loss: 1.5046\n",
      "Epoch: 261, Loss: 1.5025\n",
      "Epoch: 271, Loss: 1.4942\n",
      "Epoch: 281, Loss: 1.4892\n",
      "Epoch: 291, Loss: 1.4849\n",
      "Epoch: 301, Loss: 1.4800\n",
      "Epoch: 311, Loss: 1.4764\n",
      "Epoch: 321, Loss: 1.4791\n",
      "Epoch: 331, Loss: 1.4710\n",
      "Epoch: 341, Loss: 1.4670\n",
      "Epoch: 351, Loss: 1.4628\n",
      "Epoch: 361, Loss: 1.4597\n",
      "Epoch: 371, Loss: 1.4724\n",
      "Epoch: 381, Loss: 1.4548\n",
      "Epoch: 391, Loss: 1.4529\n",
      "Epoch: 401, Loss: 1.4499\n",
      "Epoch: 411, Loss: 1.4466\n",
      "Epoch: 421, Loss: 1.4550\n",
      "Epoch: 431, Loss: 1.4422\n",
      "Epoch: 441, Loss: 1.4402\n",
      "Epoch: 451, Loss: 1.4373\n",
      "Epoch: 461, Loss: 1.4355\n",
      "Epoch: 471, Loss: 1.4376\n",
      "Epoch: 481, Loss: 1.4352\n",
      "Epoch: 491, Loss: 1.4305\n",
      "Validation Accuracy: 0.5614\n",
      "Minimum Loss Value: 1.4305\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(323)\n",
    "model = GCN(32) # changing the hidden channels number to a value from [16,32,64]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    a = data.y[data.train_mask].resize_(len(data.train_mask))\n",
    "    loss = criterion(out[data.train_mask], a)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    b = data.y[data.val_mask].resize_(len(data.val_mask))\n",
    "    test_correct = pred[data.val_mask] == b\n",
    "    test_acc = int(test_correct.sum()) / len(data.val_mask)\n",
    "    return test_acc\n",
    "\n",
    "total_loss = []\n",
    "for i, epoch in enumerate(range(1, 501)):\n",
    "    loss = train()\n",
    "    total_loss.append(loss)\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}')\n",
    "val_acc = test()\n",
    "print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "print(f'Minimum Loss Value: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanh Hidden channels = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 3.7103\n",
      "Epoch: 11, Loss: 2.7825\n",
      "Epoch: 21, Loss: 2.3772\n",
      "Epoch: 31, Loss: 2.0791\n",
      "Epoch: 41, Loss: 1.9099\n",
      "Epoch: 51, Loss: 1.7976\n",
      "Epoch: 61, Loss: 1.7026\n",
      "Epoch: 71, Loss: 1.6408\n",
      "Epoch: 81, Loss: 1.6079\n",
      "Epoch: 91, Loss: 1.5841\n",
      "Epoch: 101, Loss: 1.5586\n",
      "Epoch: 111, Loss: 1.5379\n",
      "Epoch: 121, Loss: 1.5273\n",
      "Epoch: 131, Loss: 1.5122\n",
      "Epoch: 141, Loss: 1.4935\n",
      "Epoch: 151, Loss: 1.4799\n",
      "Epoch: 161, Loss: 1.4754\n",
      "Epoch: 171, Loss: 1.4626\n",
      "Epoch: 181, Loss: 1.4564\n",
      "Epoch: 191, Loss: 1.4444\n",
      "Epoch: 201, Loss: 1.4366\n",
      "Epoch: 211, Loss: 1.4392\n",
      "Epoch: 221, Loss: 1.4275\n",
      "Epoch: 231, Loss: 1.4214\n",
      "Epoch: 241, Loss: 1.4169\n",
      "Epoch: 251, Loss: 1.4118\n",
      "Epoch: 261, Loss: 1.4149\n",
      "Epoch: 271, Loss: 1.4086\n",
      "Epoch: 281, Loss: 1.4018\n",
      "Epoch: 291, Loss: 1.3980\n",
      "Epoch: 301, Loss: 1.3955\n",
      "Epoch: 311, Loss: 1.3932\n",
      "Epoch: 321, Loss: 1.3907\n",
      "Epoch: 331, Loss: 1.3857\n",
      "Epoch: 341, Loss: 1.3824\n",
      "Epoch: 351, Loss: 1.3805\n",
      "Epoch: 361, Loss: 1.3854\n",
      "Epoch: 371, Loss: 1.3814\n",
      "Epoch: 381, Loss: 1.3759\n",
      "Epoch: 391, Loss: 1.3713\n",
      "Epoch: 401, Loss: 1.3689\n",
      "Epoch: 411, Loss: 1.3806\n",
      "Epoch: 421, Loss: 1.3668\n",
      "Epoch: 431, Loss: 1.3719\n",
      "Epoch: 441, Loss: 1.3639\n",
      "Epoch: 451, Loss: 1.3609\n",
      "Epoch: 461, Loss: 1.3585\n",
      "Epoch: 471, Loss: 1.3574\n",
      "Epoch: 481, Loss: 1.3630\n",
      "Epoch: 491, Loss: 1.3596\n",
      "Validation Accuracy: 0.5751\n",
      "Minimum Loss Value: 1.3550\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(323)\n",
    "model = GCN(64) # changing the hidden channels number to a value from [16,32,64]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    a = data.y[data.train_mask].resize_(len(data.train_mask))\n",
    "    loss = criterion(out[data.train_mask], a)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    b = data.y[data.val_mask].resize_(len(data.val_mask))\n",
    "    test_correct = pred[data.val_mask] == b\n",
    "    test_acc = int(test_correct.sum()) / len(data.val_mask)\n",
    "    return test_acc\n",
    "\n",
    "total_loss = []\n",
    "for i, epoch in enumerate(range(1, 501)):\n",
    "    loss = train()\n",
    "    total_loss.append(loss)\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}')\n",
    "val_acc = test()\n",
    "print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "print(f'Minimum Loss Value: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCN with ReLU activation function and its' train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_relu(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(5678)\n",
    "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels//2)\n",
    "        self.classifier = Linear(hidden_channels//2, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.relu()\n",
    "        \n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU Hidden channels = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 3.6946\n",
      "Epoch: 11, Loss: 3.3078\n",
      "Epoch: 21, Loss: 3.0132\n",
      "Epoch: 31, Loss: 2.8159\n",
      "Epoch: 41, Loss: 2.5595\n",
      "Epoch: 51, Loss: 2.3915\n",
      "Epoch: 61, Loss: 2.2625\n",
      "Epoch: 71, Loss: 2.1857\n",
      "Epoch: 81, Loss: 2.1355\n",
      "Epoch: 91, Loss: 2.0962\n",
      "Epoch: 101, Loss: 2.0593\n",
      "Epoch: 111, Loss: 2.0273\n",
      "Epoch: 121, Loss: 1.9919\n",
      "Epoch: 131, Loss: 1.9536\n",
      "Epoch: 141, Loss: 1.9211\n",
      "Epoch: 151, Loss: 1.8937\n",
      "Epoch: 161, Loss: 1.8739\n",
      "Epoch: 171, Loss: 1.8569\n",
      "Epoch: 181, Loss: 1.8449\n",
      "Epoch: 191, Loss: 1.8335\n",
      "Epoch: 201, Loss: 1.8242\n",
      "Epoch: 211, Loss: 1.8155\n",
      "Epoch: 221, Loss: 1.8097\n",
      "Epoch: 231, Loss: 1.8026\n",
      "Epoch: 241, Loss: 1.7985\n",
      "Epoch: 251, Loss: 1.7946\n",
      "Epoch: 261, Loss: 1.7860\n",
      "Epoch: 271, Loss: 1.7797\n",
      "Epoch: 281, Loss: 1.7732\n",
      "Epoch: 291, Loss: 1.7681\n",
      "Epoch: 301, Loss: 1.7606\n",
      "Epoch: 311, Loss: 1.7534\n",
      "Epoch: 321, Loss: 1.7444\n",
      "Epoch: 331, Loss: 1.7374\n",
      "Epoch: 341, Loss: 1.7313\n",
      "Epoch: 351, Loss: 1.7202\n",
      "Epoch: 361, Loss: 1.7146\n",
      "Epoch: 371, Loss: 1.7108\n",
      "Epoch: 381, Loss: 1.7026\n",
      "Epoch: 391, Loss: 1.6988\n",
      "Epoch: 401, Loss: 1.6967\n",
      "Epoch: 411, Loss: 1.6966\n",
      "Epoch: 421, Loss: 1.6899\n",
      "Epoch: 431, Loss: 1.6881\n",
      "Epoch: 441, Loss: 1.6837\n",
      "Epoch: 451, Loss: 1.6810\n",
      "Epoch: 461, Loss: 1.6808\n",
      "Epoch: 471, Loss: 1.6771\n",
      "Epoch: 481, Loss: 1.6767\n",
      "Epoch: 491, Loss: 1.6737\n",
      "Validation Accuracy: 0.5161\n",
      "Minimum Loss Value: 1.6728\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(80)\n",
    "model = GCN_relu(16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    a = data.y[data.train_mask].resize_(len(data.train_mask))\n",
    "    loss = criterion(out[data.train_mask], a)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    b = data.y[data.val_mask].resize_(len(data.val_mask))\n",
    "    test_correct = pred[data.val_mask] == b\n",
    "    test_acc = int(test_correct.sum()) / len(data.val_mask)\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "total_loss = []\n",
    "for i, epoch in enumerate(range(1, 501)):\n",
    "    loss = train()\n",
    "    total_loss.append(loss)\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}')\n",
    "val_acc = test()\n",
    "print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "print(f'Minimum Loss Value: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU Hidden channels = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 3.7511\n",
      "Epoch: 11, Loss: 3.1414\n",
      "Epoch: 21, Loss: 2.7732\n",
      "Epoch: 31, Loss: 2.5956\n",
      "Epoch: 41, Loss: 2.4591\n",
      "Epoch: 51, Loss: 2.2257\n",
      "Epoch: 61, Loss: 2.1024\n",
      "Epoch: 71, Loss: 1.9948\n",
      "Epoch: 81, Loss: 1.9258\n",
      "Epoch: 91, Loss: 1.8551\n",
      "Epoch: 101, Loss: 1.8140\n",
      "Epoch: 111, Loss: 1.7841\n",
      "Epoch: 121, Loss: 1.7619\n",
      "Epoch: 131, Loss: 1.7421\n",
      "Epoch: 141, Loss: 1.7179\n",
      "Epoch: 151, Loss: 1.7007\n",
      "Epoch: 161, Loss: 1.6813\n",
      "Epoch: 171, Loss: 1.6658\n",
      "Epoch: 181, Loss: 1.6567\n",
      "Epoch: 191, Loss: 1.6426\n",
      "Epoch: 201, Loss: 1.6334\n",
      "Epoch: 211, Loss: 1.6291\n",
      "Epoch: 221, Loss: 1.6187\n",
      "Epoch: 231, Loss: 1.6160\n",
      "Epoch: 241, Loss: 1.6032\n",
      "Epoch: 251, Loss: 1.5957\n",
      "Epoch: 261, Loss: 1.5941\n",
      "Epoch: 271, Loss: 1.5849\n",
      "Epoch: 281, Loss: 1.5788\n",
      "Epoch: 291, Loss: 1.5742\n",
      "Epoch: 301, Loss: 1.5689\n",
      "Epoch: 311, Loss: 1.5812\n",
      "Epoch: 321, Loss: 1.5675\n",
      "Epoch: 331, Loss: 1.5597\n",
      "Epoch: 341, Loss: 1.5542\n",
      "Epoch: 351, Loss: 1.5512\n",
      "Epoch: 361, Loss: 1.5469\n",
      "Epoch: 371, Loss: 1.5471\n",
      "Epoch: 381, Loss: 1.5381\n",
      "Epoch: 391, Loss: 1.5358\n",
      "Epoch: 401, Loss: 1.5337\n",
      "Epoch: 411, Loss: 1.5294\n",
      "Epoch: 421, Loss: 1.5252\n",
      "Epoch: 431, Loss: 1.5222\n",
      "Epoch: 441, Loss: 1.5204\n",
      "Epoch: 451, Loss: 1.5217\n",
      "Epoch: 461, Loss: 1.5232\n",
      "Epoch: 471, Loss: 1.5137\n",
      "Epoch: 481, Loss: 1.5089\n",
      "Epoch: 491, Loss: 1.5054\n",
      "Validation Accuracy: 0.5464\n",
      "Minimum Loss Value: 1.5064\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(80)\n",
    "model = GCN_relu(32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    a = data.y[data.train_mask].resize_(len(data.train_mask))\n",
    "    loss = criterion(out[data.train_mask], a)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    b = data.y[data.val_mask].resize_(len(data.val_mask))\n",
    "    test_correct = pred[data.val_mask] == b\n",
    "    test_acc = int(test_correct.sum()) / len(data.val_mask)\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "total_loss = []\n",
    "for i, epoch in enumerate(range(1, 501)):\n",
    "    loss = train()\n",
    "    total_loss.append(loss)\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}')\n",
    "val_acc = test()\n",
    "print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "print(f'Minimum Loss Value: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU Hidden channels = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 3.6991\n",
      "Epoch: 11, Loss: 2.9125\n",
      "Epoch: 21, Loss: 2.4505\n",
      "Epoch: 31, Loss: 2.2009\n",
      "Epoch: 41, Loss: 2.0176\n",
      "Epoch: 51, Loss: 1.8775\n",
      "Epoch: 61, Loss: 1.8126\n",
      "Epoch: 71, Loss: 1.7409\n",
      "Epoch: 81, Loss: 1.7115\n",
      "Epoch: 91, Loss: 1.6672\n",
      "Epoch: 101, Loss: 1.6459\n",
      "Epoch: 111, Loss: 1.6161\n",
      "Epoch: 121, Loss: 1.5968\n",
      "Epoch: 131, Loss: 1.5805\n",
      "Epoch: 141, Loss: 1.5720\n",
      "Epoch: 151, Loss: 1.5560\n",
      "Epoch: 161, Loss: 1.5477\n",
      "Epoch: 171, Loss: 1.5367\n",
      "Epoch: 181, Loss: 1.5275\n",
      "Epoch: 191, Loss: 1.5180\n",
      "Epoch: 201, Loss: 1.5133\n",
      "Epoch: 211, Loss: 1.5156\n",
      "Epoch: 221, Loss: 1.5113\n",
      "Epoch: 231, Loss: 1.4958\n",
      "Epoch: 241, Loss: 1.4897\n",
      "Epoch: 251, Loss: 1.4843\n",
      "Epoch: 261, Loss: 1.4779\n",
      "Epoch: 271, Loss: 1.4778\n",
      "Epoch: 281, Loss: 1.4747\n",
      "Epoch: 291, Loss: 1.4674\n",
      "Epoch: 301, Loss: 1.4620\n",
      "Epoch: 311, Loss: 1.4552\n",
      "Epoch: 321, Loss: 1.4607\n",
      "Epoch: 331, Loss: 1.4496\n",
      "Epoch: 341, Loss: 1.4419\n",
      "Epoch: 351, Loss: 1.4473\n",
      "Epoch: 361, Loss: 1.4322\n",
      "Epoch: 371, Loss: 1.4340\n",
      "Epoch: 381, Loss: 1.4271\n",
      "Epoch: 391, Loss: 1.4225\n",
      "Epoch: 401, Loss: 1.4171\n",
      "Epoch: 411, Loss: 1.4157\n",
      "Epoch: 421, Loss: 1.4182\n",
      "Epoch: 431, Loss: 1.4099\n",
      "Epoch: 441, Loss: 1.4086\n",
      "Epoch: 451, Loss: 1.4091\n",
      "Epoch: 461, Loss: 1.3995\n",
      "Epoch: 471, Loss: 1.4049\n",
      "Epoch: 481, Loss: 1.3930\n",
      "Epoch: 491, Loss: 1.3925\n",
      "Validation Accuracy: 0.5619\n",
      "Minimum Loss Value: 1.4005\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(80)\n",
    "model = GCN_relu(64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    a = data.y[data.train_mask].resize_(len(data.train_mask))\n",
    "    loss = criterion(out[data.train_mask], a)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    b = data.y[data.val_mask].resize_(len(data.val_mask))\n",
    "    test_correct = pred[data.val_mask] == b\n",
    "    test_acc = int(test_correct.sum()) / len(data.val_mask)\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "total_loss = []\n",
    "for i, epoch in enumerate(range(1, 501)):\n",
    "    loss = train()\n",
    "    total_loss.append(loss)\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}')\n",
    "val_acc = test()\n",
    "print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "print(f'Minimum Loss Value: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model\n",
    "best_model_weights = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(best_model, \"GCN_best_model_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5751\n"
     ]
    }
   ],
   "source": [
    "loaded_model = torch.load(\"GCN_best_model_new.pkl\")\n",
    "loaded_model\n",
    "out_loaded = loaded_model(data.x, data.edge_index)\n",
    "b = data.y[data.val_mask].resize_(len(data.val_mask))\n",
    "pred_loaded = out_loaded.argmax(dim=1)\n",
    "test_correct_loaded = pred_loaded[data.val_mask] == b\n",
    "print(int(test_correct_loaded.sum()) / len(data.val_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe for showcasing the prediction for each paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59665\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99995</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99996</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99997</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99998</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>99999</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx  prediction\n",
       "0          0           4\n",
       "1          1           9\n",
       "2          2          28\n",
       "3          3           2\n",
       "4          4          27\n",
       "...      ...         ...\n",
       "99995  99995          26\n",
       "99996  99996           5\n",
       "99997  99997          18\n",
       "99998  99998          30\n",
       "99999  99999          34\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "len(data.x)\n",
    "idx = [i for i in range(len(data.x))]\n",
    "real_full = data.y.resize_(len(data.x))\n",
    "real_labels = real_full.numpy()\n",
    "predicted_labels = pred.numpy()\n",
    "print(accuracy_score(real_labels, predicted_labels))\n",
    "\n",
    "results = pd.DataFrame(list(zip(idx, list(predicted_labels))),\n",
    "                           columns=['idx', 'prediction'])\n",
    "\n",
    "results\n",
    "#results.to_csv('prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
